{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import  WebDriverWait\n",
    "import pandas as pd \n",
    "import time\n",
    "import re, threading\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_screenshot(driver, regnumber=\"\"):\n",
    "    try:\n",
    "        os.makedirs(\"screenshots\", exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"screenshots/{regnumber}_{timestamp}.png\"\n",
    "        driver.save_screenshot(filename)\n",
    "        print(f\"üì∏ Screenshot saved: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Screenshot failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Screenshot saved: screenshots/2005 Jaguar XJ 4.2 Special Equipment_20251110_183232.png\n",
      "No current bid\n",
      "No estimated values\n",
      "No interior card found: Message: invalid session id: session deleted as the browser has closed the connection\n",
      "from disconnected: not connected to DevTools\n",
      "  (Session info: chrome=141.0.7390.123); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x9bfe43+66515]\n",
      "\tGetHandleVerifier [0x0x9bfe84+66580]\n",
      "\t(No symbol) [0x0x7adc48]\n",
      "\t(No symbol) [0x0x79ce80]\n",
      "\t(No symbol) [0x0x7bb81b]\n",
      "\t(No symbol) [0x0x821c25]\n",
      "\t(No symbol) [0x0x83c4d9]\n",
      "\t(No symbol) [0x0x81afc6]\n",
      "\t(No symbol) [0x0x7ec2ca]\n",
      "\t(No symbol) [0x0x7ed154]\n",
      "\tGetHandleVerifier [0x0xc17353+2521315]\n",
      "\tGetHandleVerifier [0x0xc122d3+2500707]\n",
      "\tGetHandleVerifier [0x0x9e7c94+229924]\n",
      "\tGetHandleVerifier [0x0x9d81f8+165768]\n",
      "\tGetHandleVerifier [0x0x9decad+193085]\n",
      "\tGetHandleVerifier [0x0x9c8158+100072]\n",
      "\tGetHandleVerifier [0x0x9c82f0+100480]\n",
      "\tGetHandleVerifier [0x0x9b25aa+11066]\n",
      "\tBaseThreadInitThunk [0x0x75b37ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7726c3ab+107]\n",
      "\tRtlClearBits [0x0x7726c32f+191]\n",
      "\n",
      "No interior card found\n",
      "No summary found\n",
      "‚ùå No bid history found: Message: invalid session id; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x9bfe43+66515]\n",
      "\tGetHandleVerifier [0x0x9bfe84+66580]\n",
      "\t(No symbol) [0x0x7ada6b]\n",
      "\t(No symbol) [0x0x7eb5ab]\n",
      "\t(No symbol) [0x0x81b086]\n",
      "\t(No symbol) [0x0x81667c]\n",
      "\t(No symbol) [0x0x815bf3]\n",
      "\t(No symbol) [0x0x77e72d]\n",
      "\t(No symbol) [0x0x77ecae]\n",
      "\t(No symbol) [0x0x77f14d]\n",
      "\tGetHandleVerifier [0x0xc17353+2521315]\n",
      "\tGetHandleVerifier [0x0xc122d3+2500707]\n",
      "\tGetHandleVerifier [0x0x9e7c94+229924]\n",
      "\tGetHandleVerifier [0x0x9d81f8+165768]\n",
      "\tGetHandleVerifier [0x0x9decad+193085]\n",
      "\t(No symbol) [0x0x77e3e3]\n",
      "\t(No symbol) [0x0x77db60]\n",
      "\tGetHandleVerifier [0x0xd5c20f+3852191]\n",
      "\tBaseThreadInitThunk [0x0x75b37ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7726c3ab+107]\n",
      "\tRtlClearBits [0x0x7726c32f+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def scrape(path):\n",
    "    options = ChromeOptions()\n",
    "    options.headless=True\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = Chrome(service=service, options=options)\n",
    "    driver.get(path)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    \n",
    "    # =====================================================================================\n",
    "    # get the login icon and click on it \n",
    "# =====================================================================================\n",
    "#     try:\n",
    "#         # get the login button\n",
    "#         login = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/button[@data-qa=\"navbar login button\"]')))\n",
    "#         if login:\n",
    "#             driver.execute_script(\"arguments[0].scrollIntoView();\", login)\n",
    "#             login.click()\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"No login tab found and the error is {e}\")\n",
    "\n",
    "# # =====================================================================================\n",
    "#     # complete logiin info\n",
    "# # =====================================================================================\n",
    "\n",
    "#     # get the username tab\n",
    "#     try:\n",
    "#         provided_u_name = \"fourbrotherstrading@icloud.com\"            \n",
    "#         user_name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'.//input[@id=\"email\"]')))   \n",
    "#         user_name.send_keys(provided_u_name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"No username tab found and the error is {e}\")\n",
    "\n",
    "#     # get password tab\n",
    "#     try:\n",
    "#         provided_pass = \"Muhssan7865#\"\n",
    "#         password = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/input[@id=\"password\"]')))\n",
    "#         password.send_keys(provided_pass)\n",
    "#     except Exception as e:\n",
    "#         print(f\"No password tab found and the error is {e}\")\n",
    "        \n",
    "    # click login\n",
    "    # try:\n",
    "    #     log = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/button[@data-qa=\"login form button\"]')))\n",
    "    #     if log:\n",
    "    #         log.click()\n",
    "    #         # time.sleep(5)\n",
    "    # except Exception as e:\n",
    "    #     print(\"No log in\")\n",
    "    \n",
    "    # =====================================================================================\n",
    "    # handle cookies\n",
    "    # =====================================================================================\n",
    "    try:\n",
    "        cookie = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/button[@id=\"CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll\"]')))\n",
    "        if cookie:\n",
    "            cookie.click()\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(\"No cookies tab found and the error is {e}\")\n",
    "        \n",
    "    \n",
    "    # =====================================================================================\n",
    "    # get total cars\n",
    "    # =====================================================================================\n",
    "    # try:\n",
    "    #     num_cars = WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located((By.XPATH, './/div[@class=\"listing-card\"]')))\n",
    "    #     if num_cars:\n",
    "    #         # cars_list = num_cars.split(\" \")\n",
    "    #         cars =  int(len(num_cars)) # get only number\n",
    "    #         print(f\"Total {cars} of cars found\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"No number of cars found and error is {e}\")\n",
    "        \n",
    "    \n",
    "    # result\n",
    "    results = []\n",
    "    # car_count = 0\n",
    "    # while car_count < cars: #total_cars\n",
    "        \n",
    "    #     if not driver.window_handles:\n",
    "    #         print(\"Browser window closed. Stopping script.\")\n",
    "    #         break\n",
    "        \n",
    "    #     try:\n",
    "    #         page_cars= WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located((By.XPATH, './/div[@class=\"listing-card\"]')))\n",
    "            \n",
    "    #         for i in range(len(page_cars)): #total_cars\n",
    "    #             if car_count >= cars:\n",
    "    #                 break\n",
    "                \n",
    "                # try:\n",
    "                #     page_cars = WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located((By.XPATH, './/div[@class=\"listing-card\"]')))\n",
    "                #     driver.execute_script(\"arguments[0].scrollIntoView();\", page_cars[i])\n",
    "                #     # time.sleep(1)\n",
    "                #     page_cars[i].click()\n",
    "                #     time.sleep(2)\n",
    "\n",
    "    details = {}\n",
    "\n",
    "    # car name --> done\n",
    "    try:\n",
    "        title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"hero-headline__title\"]/h1'))).text.strip()\n",
    "        if title:\n",
    "            details['Title'] = title\n",
    "        else:\n",
    "            details['Title'] = \"na\"\n",
    "        save_full_screenshot(driver,details['Title'])\n",
    "    except Exception as e:\n",
    "        print(f\"No car title \")\n",
    "    \n",
    "    # end date time\n",
    "    try:\n",
    "        end_dt = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/span[@class=\"end-date\"]'))).text.strip()\n",
    "        if end_dt:\n",
    "            details['Auc_end'] = end_dt\n",
    "        else:\n",
    "            details['Auc_end'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No auc end\")\n",
    "    \n",
    "    # current bid\n",
    "    try:\n",
    "        curr_bid =WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/p[@data-qa=\"listing highest bid\"]'))).text.strip() \n",
    "        if curr_bid:\n",
    "            details['Current_bid'] = curr_bid\n",
    "        else:\n",
    "            details['Current_bid'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No current bid\")\n",
    "    \n",
    "    # no bids\n",
    "    try:\n",
    "        num_bids = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/span[@data-qa=\"listing bid count\"]'))).text.strip() \n",
    "        if num_bids:\n",
    "            details['No:bids'] = num_bids\n",
    "        else:\n",
    "            details['No:bids'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No num bids\")\n",
    "    \n",
    "    # key facts --> done\n",
    "    try:\n",
    "        facts_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-info-details__key-facts\"]')))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", facts_card)\n",
    "        if facts_card:\n",
    "            facts_lbl = WebDriverWait(facts_card, 5).until(EC.presence_of_element_located((By.TAG_NAME, 'h3'))).text.strip()\n",
    "            if facts_lbl:\n",
    "                # print(\"Label got\")\n",
    "                facts_ul = WebDriverWait(facts_card, 5).until(EC.presence_of_element_located((By.TAG_NAME, 'ul')))\n",
    "                if facts_ul:\n",
    "                    # print(\"Ul found\")\n",
    "                    facts_vals =  WebDriverWait(facts_ul, 5).until(EC.presence_of_all_elements_located((By.TAG_NAME, 'li')))\n",
    "                    if facts_vals:\n",
    "                        # print(\"Facts found li\")\n",
    "                        fact_values = [fact_val.text.strip() for fact_val in facts_vals]\n",
    "                        details[facts_lbl] = fact_values\n",
    "                    else:\n",
    "                        print(\"No facts data\")\n",
    "    except Exception as e:\n",
    "        print(f\"No facts data\")\n",
    "    \n",
    "    # other information --> done\n",
    "    try:\n",
    "        det_card =WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-info-details__stats\"]'))) \n",
    "        if det_card:\n",
    "            # print(\"det found\")\n",
    "            det_ul = WebDriverWait(det_card, 5).until(EC.presence_of_element_located((By.TAG_NAME, 'ul')))\n",
    "            if det_ul:\n",
    "                # print(\"ul found\")\n",
    "                det_vals =  WebDriverWait(det_ul, 5).until(EC.presence_of_all_elements_located((By.TAG_NAME, 'li')))\n",
    "                if det_vals:\n",
    "                    lbl_lst = []\n",
    "                    for li in det_vals:\n",
    "                        lbls = li.get_attribute(\"data-qa\").split(\" \")[3]\n",
    "                        lbl_lst.append(lbls)\n",
    "                        \n",
    "                        spans = li.find_elements(By.XPATH, './/span[@class=\"icon-text is-capitalized\"]')\n",
    "                        if spans:\n",
    "                            for span in spans:\n",
    "                                vals = span.find_element(By.XPATH, './/span[@class=\"text\"]').text.strip()\n",
    "                                details[lbls] = vals\n",
    "                    # results.append(dict(zip(lbl_lst, vals)))\n",
    "    except Exception as e:\n",
    "        print(f\"No car dets\")\n",
    "        \n",
    "    # location --> done\n",
    "    try:\n",
    "        loc_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-info-details__location\"]'))) \n",
    "        if loc_card:\n",
    "            loc_lbl = loc_card.find_element(By.TAG_NAME, 'h6').text.strip()\n",
    "            loc_val = loc_card.find_element(By.XPATH, './/span[@class=\"text\"]').text.strip()\n",
    "            if loc_lbl and loc_val:\n",
    "                details[loc_lbl] = loc_val\n",
    "            else:\n",
    "                print(\"No loc infor\")\n",
    "    except Exception as e:\n",
    "        print(\"No loc infor\")\n",
    "        \n",
    "    # bg dets --> done\n",
    "    try:\n",
    "        bg_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content background\"])[1]'))) \n",
    "        if bg_card:\n",
    "            bg_dets = WebDriverWait(bg_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))).text.strip()\n",
    "            if bg_dets:\n",
    "                details['Background'] = bg_dets\n",
    "            else:\n",
    "                details['Background'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No bg card found\")\n",
    "        \n",
    "    # overview dets --> done\n",
    "    try:\n",
    "        over_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content overview\"])[1]'))) \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", over_card)\n",
    "        if over_card:\n",
    "            over_dets = WebDriverWait(over_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))).text.strip()\n",
    "            if over_dets:\n",
    "                details['Overview'] = over_dets\n",
    "            else:\n",
    "                details['Overview'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No overview card found\")\n",
    "        \n",
    "    # est val and seller --> done\n",
    "    try:\n",
    "        est_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-about__details\"]'))) \n",
    "        if est_card:\n",
    "            \n",
    "            # set val --> done\n",
    "            try:\n",
    "                est = WebDriverWait(est_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-about__estimated\"]')))\n",
    "                if est:\n",
    "                    est_lbl = est.find_element(By.TAG_NAME, 'p').text.strip()\n",
    "                    est_val = est.find_element(By.XPATH, './/span[@class=\"text\"]').text.strip()\n",
    "                    if est_lbl and est_val:\n",
    "                        details[est_lbl] = est_val\n",
    "            except Exception as e:\n",
    "                print(\"No estimated values\")\n",
    "                \n",
    "            # seller --> done\n",
    "            try:\n",
    "                sell = WebDriverWait(est_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"auction-about__seller\"]')))\n",
    "                if sell:\n",
    "                    sell_lbl = sell.find_element(By.TAG_NAME, 'p').text.strip()\n",
    "                    sell_val = sell.find_element(By.XPATH, './/span[@class=\"text\"]').text.strip()\n",
    "                    if sell_lbl and sell_val:\n",
    "                        details[sell_lbl] = sell_val\n",
    "            except Exception as e:\n",
    "                print(\"No seller values\")\n",
    "    except Exception as e:\n",
    "        print(\"No seller dets\")\n",
    "        \n",
    "    # Exterior dets and images --> done\n",
    "    try:\n",
    "        ext_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content exterior\"])[1]'))) \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", ext_card)\n",
    "        if ext_card:\n",
    "            ext_dets = WebDriverWait(ext_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))).text.strip()\n",
    "            if ext_dets:\n",
    "                details['exterior'] = ext_dets\n",
    "            else:\n",
    "                details['exterior'] = 'na'\n",
    "            \n",
    "            try:\n",
    "                # imgs\n",
    "                to_clk = WebDriverWait(ext_card, 5).until(EC.presence_of_element_located((By.XPATH, './/a[@class=\"vehicle-gallery__overlay\"]'))) \n",
    "                if to_clk:\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", to_clk)\n",
    "                    to_clk.click()\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    img_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//div[@id=\"productGallery\"])')))\n",
    "                    if img_card:\n",
    "                        imgs = WebDriverWait(img_card, 5).until(EC.presence_of_all_elements_located((By.XPATH, './/img[@class=\" twic-done\"]')))\n",
    "                        if imgs:\n",
    "                            imgs_lst = [img.get_attribute(\"src\") for img in imgs]\n",
    "                            details['Exterior_Images'] = \", \".join(imgs_lst)\n",
    "                        else:\n",
    "                            print(\"No images \")\n",
    "            except Exception as e:\n",
    "                print(\"No exterior images found\")   \n",
    "            driver.back()     \n",
    "    except Exception as e:\n",
    "        print(\"No exterior card found\")\n",
    "    \n",
    "\n",
    "    try:\n",
    "        intr_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content interior\"])[1]'))) \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", intr_card)\n",
    "        if intr_card:\n",
    "            intr_dets = WebDriverWait(intr_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))).text.strip()\n",
    "            if intr_dets:\n",
    "                details['interior'] = intr_dets\n",
    "            else:\n",
    "                details['interior'] = 'na'\n",
    "            \n",
    "            try:\n",
    "                intr_card = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content interior\"])[1]'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", intr_card)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Try clicking gallery if available\n",
    "                try:\n",
    "                    gallery_link = intr_card.find_element(By.XPATH, './/a[contains(@class,\"vehicle-gallery__overlay\")]')\n",
    "                    gallery_link.click()\n",
    "                    time.sleep(2)\n",
    "                except:\n",
    "                    print(\"No overlay to click, checking directly for images.\")\n",
    "\n",
    "                # Get all image URLs from the gallery\n",
    "                imgs = driver.find_elements(By.XPATH, '//img[contains(@src, \"bonhamscarsonline.twic.pics\")]')\n",
    "                if imgs:\n",
    "                    imgs_lst = [img.get_attribute(\"src\") for img in imgs]\n",
    "                    details[\"interior_Images\"] = \", \".join(imgs_lst)\n",
    "                    print(f\"‚úÖ Found {len(imgs_lst)} interior images\")\n",
    "                else:\n",
    "                    print(\"No interior images found\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"No interior card found: {e}\")\n",
    "\n",
    "            driver.back()   \n",
    "    except Exception as e:\n",
    "        print(\"No interior card found\")\n",
    "            \n",
    "    # Mechanical dets and images --> done\n",
    "    try:\n",
    "        mech_card = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content mechanical\"])[1]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", mech_card)\n",
    "\n",
    "        # Mechanical details text\n",
    "        try:\n",
    "            mech_dets = WebDriverWait(mech_card, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))\n",
    "            ).text.strip()\n",
    "            details[\"mechanical\"] = mech_dets if mech_dets else \"na\"\n",
    "        except:\n",
    "            details[\"mechanical\"] = \"na\"\n",
    "\n",
    "        # Mechanical images\n",
    "        try:\n",
    "            to_clk = WebDriverWait(mech_card, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, './/a[@class=\"vehicle-gallery__overlay\"]'))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", to_clk)\n",
    "            to_clk.click()\n",
    "\n",
    "            img_card = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '(.//div[@id=\"productGallery\"])'))\n",
    "            )\n",
    "            imgs = WebDriverWait(img_card, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, './/img[@class=\" twic-done\"]'))\n",
    "            )\n",
    "            imgs_lst = [img.get_attribute(\"src\") for img in imgs]\n",
    "            details[\"mechanical_Images\"] = \", \".join(imgs_lst) if imgs_lst else \"na\"\n",
    "\n",
    "            driver.back()\n",
    "\n",
    "        except:\n",
    "            details[\"mechanical_Images\"] = \"na\"\n",
    "\n",
    "    except:\n",
    "        details[\"mechanical\"] = \"na\"\n",
    "        details[\"mechanical_Images\"] = \"na\"\n",
    "\n",
    "            \n",
    "    # History dets and images --> done\n",
    "    try:\n",
    "        hist_card = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content history\"])[1]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", hist_card)\n",
    "\n",
    "        # History text\n",
    "        try:\n",
    "            hist_dets = WebDriverWait(hist_card, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))\n",
    "            ).text.strip()\n",
    "            details[\"History\"] = hist_dets if hist_dets else \"na\"\n",
    "        except:\n",
    "            details[\"History\"] = \"na\"\n",
    "\n",
    "        # History images\n",
    "        try:\n",
    "            to_clk = WebDriverWait(hist_card, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '(.//a[@class=\"mt-2\"])[1]'))\n",
    "            )\n",
    "            to_clk.click()\n",
    "\n",
    "            img_card = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '(.//div[@id=\"productGallery\"])'))\n",
    "            )\n",
    "            imgs = WebDriverWait(img_card, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, './/img[@class=\" twic-done\"]'))\n",
    "            )\n",
    "            imgs_lst = [img.get_attribute(\"src\") for img in imgs]\n",
    "            details[\"History_Images\"] = \", \".join(imgs_lst) if imgs_lst else \"na\"\n",
    "\n",
    "            driver.back()\n",
    "\n",
    "        except:\n",
    "            details[\"History_Images\"] = \"na\"\n",
    "\n",
    "    except:\n",
    "        details[\"History\"] = \"na\"\n",
    "        details[\"History_Images\"] = \"na\"\n",
    "\n",
    "        \n",
    "    # Summary dets --> done\n",
    "    try:\n",
    "        summary_card = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '(.//article[@data-qa=\"auction content summary\"])[1]'))) \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", summary_card)\n",
    "        if summary_card:\n",
    "            summary_dets = WebDriverWait(summary_card, 5).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"content__inner\"]'))).text.strip()\n",
    "            if summary_dets:\n",
    "                details['Summary'] = summary_dets\n",
    "            else:\n",
    "                details['Summary'] = 'na'\n",
    "    except Exception as e:\n",
    "        print(\"No summary found\")\n",
    "    \n",
    "    # bids\n",
    "    try:\n",
    "        # Wait for all bid comment cards\n",
    "        comments = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//article[@class=\"comments__activity level\"]'))\n",
    "        )\n",
    "\n",
    "        bids_data = []\n",
    "\n",
    "        for comment in comments:\n",
    "            try:\n",
    "                username = comment.find_element(By.XPATH, './/span[contains(@class,\"bid-comment__username\")]').text.strip()\n",
    "            except:\n",
    "                username = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                amount = comment.find_element(By.XPATH, './/span[contains(@class,\"bid-comment__amount\")]').text.strip()\n",
    "            except:\n",
    "                amount = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                time_text = comment.find_element(By.XPATH, './/span[contains(@class,\"bid-comment__time\")]').text.strip()\n",
    "            except:\n",
    "                time_text = \"N/A\"\n",
    "\n",
    "            # Combine one record\n",
    "            bids_data.append(f\"{username} - {amount} - {time_text}\")\n",
    "\n",
    "        if bids_data:\n",
    "            # Convert list to comma separated string\n",
    "            details[\"Bids_History\"] = \", \".join(bids_data)\n",
    "        else:\n",
    "            details[\"Bids_History\"] = \"na\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå No bid history found:\", e)\n",
    "        details[\"Bids_History\"] = \"na\"\n",
    "\n",
    "\n",
    "    \n",
    "    # car_count+=1\n",
    "    results.append(details)\n",
    "                    # driver.back()\n",
    "                    \n",
    "        #         except Exception as e:\n",
    "        #             print(\"No more cars to click\")\n",
    "        #             # break\n",
    "        # except Exception as e:\n",
    "        #     print(\"No more cars\")\n",
    "        #     # break\n",
    "        \n",
    "    # time.sleep(5)\n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    df.to_csv(\"Bonhams.csv\", index=False)\n",
    "    driver.quit()\n",
    "\n",
    "path = \"https://carsonline.bonhams.com/en/listings/jaguar/xj-42-special-equipment/d0f91d7a-5758-4cf1-ac3e-317a18469d81\"\n",
    "scrape(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Auc_end', 'No:bids', 'Key Facts', 'chassis', 'mileage',\n",
       "       'engine', 'gearbox', 'color', 'interior', 'steering', 'fuel_type',\n",
       "       'Vehicle location', 'Background', 'Overview', 'Seller', 'exterior',\n",
       "       'Exterior_Images', 'mechanical', 'mechanical_Images', 'History',\n",
       "       'History_Images', 'Bids_History'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Bonhams.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exterior images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['interior_Images'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBonhams.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m ext_img \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExterior_Images\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m---> 48\u001b[0m int_img \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterior_Images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     49\u001b[0m mech_img \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmechanical_Images\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# reg_img = df[[\"Title\", \"History_Images\"]]\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# hist_img = df[[\"Title\", \"History_Images\"]]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['interior_Images'] not in index\""
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse, urljoin,urlunparse\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def add_watermark_to_image(image_path, text=\"Sourced from Bonhams\"):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGBA\")\n",
    "        txt_layer = Image.new(\"RGBA\", image.size, (255, 255, 255, 0))\n",
    "        draw = ImageDraw.Draw(txt_layer)\n",
    "\n",
    "        # üîπ Slightly smaller dynamic font size (half previous)\n",
    "        font_size = max(20, image.width // 50)  # reduced from //25 ‚Üí //50\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Calculate text size and position\n",
    "        margin = int(font_size * 0.6)\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        x = image.width - text_width - margin\n",
    "        y = image.height - text_height - margin\n",
    "\n",
    "        # Draw semi-transparent background box\n",
    "        box_padding = int(font_size * 0.4)\n",
    "        draw.rectangle(\n",
    "            [x - box_padding, y - box_padding, x + text_width + box_padding, y + text_height + box_padding],\n",
    "            fill=(0, 0, 0, 180)\n",
    "        )\n",
    "\n",
    "        # Draw watermark text\n",
    "        draw.text((x, y), text, font=font, fill=(255, 255, 255, 240))\n",
    "\n",
    "        # Merge and save\n",
    "        watermarked = Image.alpha_composite(image, txt_layer).convert(\"RGB\")\n",
    "        watermarked.save(image_path)\n",
    "        print(f\"‚úÖ Watermark added to {image_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to watermark {image_path}: {e}\")\n",
    "\n",
    "        \n",
    "df = pd.read_csv(\"Bonhams.csv\")\n",
    "ext_img = df[[\"Title\", \"Exterior_Images\"]]\n",
    "int_img = df[[\"Title\", \"interior_Images\"]]\n",
    "mech_img = df[[\"Title\", \"mechanical_Images\"]]\n",
    "# reg_img = df[[\"Title\", \"History_Images\"]]\n",
    "# hist_img = df[[\"Title\", \"History_Images\"]]\n",
    "def clean_image_url(url):\n",
    "    \"\"\"\n",
    "    Removes resizing or twic query parameters from the image URL.\n",
    "    Example:\n",
    "    https://example.com/image.jpg?twic=v1/resize=650 -> https://example.com/image.jpg\n",
    "    \"\"\"\n",
    "    return url.split(\"?\")[0].strip()\n",
    "\n",
    "def download_images(data, column_name, main_folder):\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        reg_no = row[\"Title\"]\n",
    "        image_urls = row[column_name]\n",
    "\n",
    "        if pd.isna(image_urls) or not isinstance(image_urls, str) or image_urls.strip() == \"\":\n",
    "            print(f\"Skipping {reg_no} (No image URLs)\")\n",
    "            continue\n",
    "\n",
    "        image_urls = image_urls.split(\", \")\n",
    "        reg_folder = os.path.join(main_folder, reg_no)\n",
    "        os.makedirs(reg_folder, exist_ok=True)\n",
    "\n",
    "        for idx, url in enumerate(image_urls):\n",
    "            url = clean_image_url(url.strip())\n",
    "            if not url.startswith((\"http://\", \"https://\")):\n",
    "                url = urljoin(\"https://\", url)\n",
    "\n",
    "            parsed_url = urlparse(url)\n",
    "            if not parsed_url.scheme or not parsed_url.netloc:\n",
    "                print(f\"Invalid URL skipped: {url}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, stream=True, timeout=10)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                file_name = os.path.basename(parsed_url.path) or f\"image_{idx + 1}.jpg\"\n",
    "                file_extension = file_name.split(\".\")[-1].lower()\n",
    "                if file_extension not in [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"webp\"]:\n",
    "                    file_name = f\"image_{idx + 1}.jpg\"\n",
    "\n",
    "                full_file_name = os.path.join(reg_folder, f\"{reg_no}_{idx + 1}_{file_name}\")\n",
    "                with open(full_file_name, 'wb') as f:\n",
    "                    for chunk in response.iter_content(1024):\n",
    "                        f.write(chunk)\n",
    "\n",
    "                print(f\"‚úÖ Downloaded: {full_file_name}\")\n",
    "                add_watermark_to_image(full_file_name)  # üíß Add watermark after saving\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to download {url} for {reg_no}: {e}\")\n",
    "\n",
    "# ‚úÖ Specific Wrappers for each image type\n",
    "def download_ext(data): \n",
    "    download_images(data, \"Exterior_Images\", \"Exterior_Images\")\n",
    "\n",
    "def download_int(data): \n",
    "    download_images(data, \"interior_Images\", \"interior_Images\")\n",
    "\n",
    "def download_mech(data): \n",
    "    download_images(data, \"mechanical_Images\", \"mechanical_Images\")\n",
    "\n",
    "# hist images \n",
    "# def download_hist(data, main_folder=\"History_Images\"): \n",
    "#     os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "#     for index, row in data.iterrows():\n",
    "#         reg_no = row[\"Title\"] \n",
    "#         image_urls = row[\"History_Images\"]\n",
    "\n",
    "#         # Check if 'Images' column is empty or NaN\n",
    "#         if pd.isna(image_urls) or not isinstance(image_urls, str) or image_urls.strip() == \"\":\n",
    "#             print(f\"Skipping {reg_no} (No image URLs)\")\n",
    "#         else:\n",
    "#             image_urls = image_urls.split(\", \")  # Split URLs by comma\n",
    "            \n",
    "#             reg_folder = os.path.join(main_folder, reg_no)\n",
    "#             os.makedirs(reg_folder, exist_ok=True)\n",
    "            \n",
    "#             for idx, url in enumerate(image_urls):\n",
    "#                 url = url.strip()\n",
    "#                 if not url.startswith((\"http://\", \"https://\")):\n",
    "#                     url = urljoin(\"https://\", url) \n",
    "                \n",
    "#                 parsed_url = urlparse(url)\n",
    "#                 if not parsed_url.scheme or not parsed_url.netloc:\n",
    "#                     print(f\"Invalid URL skipped: {url}\") \n",
    "#                     continue\n",
    "                \n",
    "#                 try:\n",
    "#                     response = requests.get(url, stream=True) \n",
    "#                     response.raise_for_status()\n",
    "                    \n",
    "#                     file_name = os.path.basename(parsed_url.path) or f\"image_{idx + 1}.jpg\"\n",
    "#                     file_extension = file_name.split(\".\")[-1]\n",
    "                    \n",
    "#                     if file_extension not in [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"webp\"]:\n",
    "#                         file_name = f\"image_{idx + 1}.jpg\"\n",
    "                    \n",
    "#                     full_file_name = os.path.join(reg_folder, f\"{reg_no}_{idx + 1}_{file_name}\")\n",
    "                    \n",
    "#                     with open(full_file_name, 'wb') as f:\n",
    "#                         for chunk in response.iter_content(1024):\n",
    "#                             f.write(chunk)\n",
    "                    \n",
    "#                     print(f\"Downloaded: {full_file_name}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Failed to download {url} for {reg_no}: {e}\")\n",
    "\n",
    "def start_funcs():\n",
    "    thread1 = threading.Thread(target=download_ext, args=(ext_img,))\n",
    "    thread2 = threading.Thread(target=download_int, args=(int_img,))\n",
    "    thread3 = threading.Thread(target=download_mech, args=(mech_img,))\n",
    "    # thread4 = threading.Thread(target=download_hist, args=(hist_img,))\n",
    "    \n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    thread3.start()\n",
    "    # thread4.start()\n",
    "    \n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    thread3.join() \n",
    "    # thread4.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_funcs()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
